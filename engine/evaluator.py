import os
from engine import model_used, exp_used, test_param, exp
if exp_used == 'super_resolution':
    from engine import test_batch_size
    from data.loader import test_loader
    loader = test_loader(test_batch_size)
import torch
import matplotlib.pyplot as plt
import importlib
from tqdm import tqdm
from engine.utils import mse, ssim, psnr

test_step = importlib.import_module(f'models.{model_used}.test_step')
test_step.model.eval()


def model1(chkpt: str):
    test_step.model.load_state_dict(torch.load(f'checkpoints/{model_used}/{chkpt}')['model'])
    m1,m2,m3 = 0,0,0
    plt.style.use('dark_background')
    fig, (ax1,ax2) = plt.subplots(1,2)
    for file in os.listdir(f'predictions/{exp_used}'):
        os.remove(f'predictions/{exp_used}/{file}')
    for i,(in_data,lab_data) in enumerate(tqdm(loader, desc=f'Evaluating model')):
        pred = test_step.run(in_data)
        m1 += mse(lab_data, pred)
        m2 += ssim(lab_data, pred)
        m3 += psnr(lab_data, pred)
        ax1.imshow(in_data[0][0], cmap='hot')
        ax1.axis('off')
        ax1.set_title('Input LR',fontsize=15,fontweight='bold',pad=10)
        ax2.imshow(pred[0][0], cmap='hot')
        ax2.axis('off')
        ax2.set_title('Pred HR',fontsize=15,fontweight='bold',pad=10)
        fig.savefig(f'predictions/{exp_used}/sample_{i}.png', bbox_inches='tight')
    print(f"\nMSE: {m1/(i+1)} \t  SSIM: {m2/(i+1)} \t  PSNR: {m3/(i+1)}\n")
    print('Sample predictions generated!\n')

def model2(chkpt):
    test_step.model.load_state_dict(torch.load(f'checkpoints/{model_used}/{chkpt}')['model'])
    for file in os.listdir(f'predictions/{exp_used}'):
        os.remove(f'predictions/{exp_used}/{file}')
    for i in range(test_param.samples):
        e = torch.randn((1,150,150))
        T = exp.timesteps
        x = test_step.run(e, T)
        for t in tqdm(range(T-1,0,-1),desc=f'Sample: {i+1}/{test_param.samples}'):
            if t==1:
                x = test_step.run(x, t, last=True)
            else:
                x = test_step.run(x, t)
        if x.shape[0]==3:
            img = x-torch.stack([torch.min(x[i]) for i in range(3)]).unsqueeze(1).unsqueeze(2)
        if x.shape[0]==1:
            img = (x - torch.min(x))/torch.max(x)
        plt.style.use('dark_background')
        plt.imshow(img[0].detach(), cmap='hot')
        plt.title('Sample generated by denoising',fontsize=15,fontweight='bold',pad=10)
        plt.axis('off')
        plt.savefig(f'predictions/{exp_used}/sample_{i}.png', bbox_inches='tight')
    print('\nSample predictions generated!\n')


def run(chkpt: str):
    if exp_used == 'super_resolution':
        model1(chkpt)
    if exp_used == 'diffusion':
        model2(chkpt)


